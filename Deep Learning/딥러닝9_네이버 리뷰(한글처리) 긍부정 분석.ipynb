{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89348840",
   "metadata": {},
   "source": [
    "##  네이버에서 크롤링한 영화 리뷰 데이터의 긍/부정 분석"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f0cb3b",
   "metadata": {},
   "source": [
    "### 네이버 영화 리뷰 데이터\n",
    "- 리뷰 작성자가 준 평점이 0.5보다 크면 1로, 이하면 0으로 라벨링해놓은 데이터\n",
    "- 한글 데이터이므로 영문 전처리와는 다르게 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e8aed69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f4f93b",
   "metadata": {},
   "source": [
    "### 데이터 전처리\n",
    "- 불용어 제거 (ㄱ-ㅎ, ㅏ-ㅜ 등 한글 자모음이 아닌 나머지는 제외)\n",
    "    - 정규식에서 한글 글자 표현 : 가-힣\n",
    "    - 불용어는 파일을 이용하는 것이 좋음\n",
    "- 리뷰를 토큰화\n",
    "    - 학습/테스트 데이터 numpy 파일 저장\n",
    "    - 토큰화 시 생성된 어휘사전 json 파일로 저장\n",
    "- 한글 토큰화 패키지\n",
    "    - konlp 패키지 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "785833cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9976970</td>\n",
       "      <td>아 더빙.. 진짜 짜증나네요 목소리</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3819312</td>\n",
       "      <td>흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10265843</td>\n",
       "      <td>너무재밓었다그래서보는것을추천한다</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9045019</td>\n",
       "      <td>교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6483659</td>\n",
       "      <td>사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                           document  label\n",
       "0   9976970                                아 더빙.. 진짜 짜증나네요 목소리      0\n",
       "1   3819312                  흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나      1\n",
       "2  10265843                                  너무재밓었다그래서보는것을추천한다      0\n",
       "3   9045019                      교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정      0\n",
       "4   6483659  사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...      1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv('./data/ratings_train.txt',header=0, delimiter='\\t', \n",
    "                         quoting=3)\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17b7be6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습데이터 전체 개수 :  150002\n"
     ]
    }
   ],
   "source": [
    "print('학습데이터 전체 개수 : ', len(train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71784fdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    19\n",
       "1    33\n",
       "2    17\n",
       "3    29\n",
       "4    61\n",
       "Name: document, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 리뷰 문자 길이 확인\n",
    "train_length = train_data['document'].astype(str).apply(len)\n",
    "train_length.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a62330f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "리뷰 길이 최댓값 : 158\n",
      "리뷰 길이 최솟값 : 1\n",
      "리뷰 길이 평균값 : 35.24\n",
      "리뷰 길이 표준편차 : 29.58\n",
      "리뷰 길이 중간값 : 27.0\n",
      "리뷰 길이 재1사분위 : 16.0\n",
      "리뷰 길이 제3사분위 : 42.0\n"
     ]
    }
   ],
   "source": [
    "# 리뷰 통계정보\n",
    "print('리뷰 길이 최댓값 : {}'.format(np.max(train_length)))\n",
    "print('리뷰 길이 최솟값 : {}'.format(np.min(train_length)))\n",
    "print('리뷰 길이 평균값 : {:.2f}'.format(np.mean(train_length)))\n",
    "print('리뷰 길이 표준편차 : {:.2f}'.format(np.std(train_length)))\n",
    "print('리뷰 길이 중간값 : {}'.format(np.median(train_length)))\n",
    "print('리뷰 길이 재1사분위 : {}'.format(np.percentile(train_length, 25)))\n",
    "print('리뷰 길이 제3사분위 : {}'.format(np.percentile(train_length, 75)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5e0ff4a",
   "metadata": {},
   "source": [
    "- 리뷰의 평균 길이 : 35.24\n",
    "- 중간값과 차이가 있고, 편차가 29 정도인 것을 보아 리뷰 길이 범위 차이가 많이 남"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "82ac9f5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    75173\n",
       "1    74829\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f9f3718d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "리뷰1(긍정) 74829\n",
      "리뷰0(부정) 75173\n"
     ]
    }
   ],
   "source": [
    "# 긍/부정 리뷰 수 확인\n",
    "print('리뷰1(긍정)', train_data['label'].value_counts()[1])\n",
    "print('리뷰0(부정)', train_data['label'].value_counts()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6bbd7f8",
   "metadata": {},
   "source": [
    "### 긍/부정 분석을 위한 자연어 처리\n",
    "- 문자열 데이터를 수치화하기 위한 작업"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1874b0bd",
   "metadata": {},
   "source": [
    "### 데이터 전처리\n",
    "- 5단계로 진행\n",
    "\n",
    "1. 정규화로 한국어만 남기기\n",
    "2. 형태소 분석기로 어간 추출하기\n",
    "    - 토큰화\n",
    "3. 불용어 제거하기\n",
    "4. 문자를 인덱스 벡터로 전환하기\n",
    "5. 패딩 처리하기\n",
    "\n",
    "\n",
    "- 한국어 텍스트를 전처리할 때는 konlpy의 okt()를 사용하여 형태소 분석\n",
    "    - okt()는 트위터사에서 제작한 한글 형태소 분석기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8b163e7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting konlpy\n",
      "  Using cached konlpy-0.6.0-py2.py3-none-any.whl (19.4 MB)\n",
      "Collecting JPype1>=0.7.0 (from konlpy)\n",
      "  Downloading JPype1-1.4.1-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (465 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m465.6/465.6 kB\u001b[0m \u001b[31m33.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: lxml>=4.1.0 in /home/ubuntu/anaconda3/envs/tensorflow2_p38/lib/python3.8/site-packages (from konlpy) (4.8.0)\n",
      "Requirement already satisfied: numpy>=1.6 in /home/ubuntu/anaconda3/envs/tensorflow2_p38/lib/python3.8/site-packages (from konlpy) (1.24.4)\n",
      "Requirement already satisfied: packaging in /home/ubuntu/anaconda3/envs/tensorflow2_p38/lib/python3.8/site-packages (from JPype1>=0.7.0->konlpy) (21.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /home/ubuntu/anaconda3/envs/tensorflow2_p38/lib/python3.8/site-packages (from packaging->JPype1>=0.7.0->konlpy) (2.4.7)\n",
      "Installing collected packages: JPype1, konlpy\n",
      "Successfully installed JPype1-1.4.1 konlpy-0.6.0\n"
     ]
    }
   ],
   "source": [
    "!pip install konlpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "60865e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re  # 정규식 적용해주는 패키지\n",
    "import json  # 어휘사전 저장 및 load\n",
    "\n",
    "# 한글 형태소 분석기 okt\n",
    "# open korea text (트위터에서 제작 - 현재 다른 기관에서 프로젝트 진행)\n",
    "import konlpy\n",
    "from konlpy.tag import Okt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bd040b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1756525a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                  아 더빙.. 진짜 짜증나네요 목소리\n",
       "1                    흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나\n",
       "2                                    너무재밓었다그래서보는것을추천한다\n",
       "3                        교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정\n",
       "4    사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...\n",
       "Name: document, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['document'][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3be573b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'가나다                   뮤직'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. 한글과 공백 제외 모두 제거\n",
    "import re\n",
    "\n",
    "# re.sub() : 어떤 패턴을 특정 문자열로 대체\n",
    "# 모든 한글글자, 한글 자/모음을 제외한 나머지 글자는 공백으로 대체\n",
    "# 제외 정규식 '[^정규식패턴]'\n",
    "re.sub('[^가-힣 ㄱ-ㅎ ㅏ-ㅣ\\\\s ]',' ','가나다 abcde ^%$##$ 1234 뮤직')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16247415",
   "metadata": {},
   "source": [
    "- 한글이 아닌 영문과 특수문자는 공백으로 대체됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3bc3ef8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'교도소 이야기구먼   솔직히 재미는 없다  평점 조정'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review = '교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정'\n",
    "review_text = re.sub('[^가-힣 ㄱ-ㅎ ㅏ-ㅣ\\\\s ]',' ',review)\n",
    "review_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca1829c5",
   "metadata": {},
   "source": [
    "### 한글 형태소 단위 토크나이징\n",
    "- KoNLPy 사용\n",
    "    - KoNLPy에서는 여러 형태소 분석기를 제공하며, 각 형태소 분석기별로 분석한 결과는 다를 수 있다.\n",
    "    - 각 형태소 분석기는 클래스 형태로 되어 있고 이를 객체로 생성한 후 매서드를 호출해서 토크나이징할 수 있다.\n",
    "\n",
    "- 형태소 분석 및 품사 태깅\n",
    "    - 형태소란 의미를 가지는 가장 작은 단위로서 더 쪼개지면 의미를 상실하는 것들을 말한다.\n",
    "    - 형태소 분석이란 의미를 가지는 단위를 기준으로 문장을 살펴보는 것을 의미한다.\n",
    "    - KoNLPy는 기존에 C, C++, Java 등의 언어를 통해 형태소 분석을 할 수 있는 좋은 라이브러리들을 파이썬 라이브러리로 통합해서 사용할 수 있록 하여 한국어 구문 분석을 쉽게 할 수 있도록 만들어진 라이브러리이다.\n",
    "    - KoNLPy에는 다양한 형태소 분석기들이 객체 형태로 포함돼 있으며 다음과 같은 각 형태소 분석기 목록이 있다.\n",
    "        - Hannanum\n",
    "        - Kkma\n",
    "        - Komoran\n",
    "        - Mecab\n",
    "        - Okt(Twitter)\n",
    "        - 모두 동일한 형태소 분석 기능 제공하지만 각기 성능이 조금씩 다름"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8608b3cd",
   "metadata": {},
   "source": [
    "- Okt 사용\n",
    "    1. 객체 생성\n",
    "        - Okt() 생성자 함수 사용\n",
    "    2. 필요 함수 사용\n",
    "        - Okt.morphs() 텍스트를 형태소 단위로 나눈다.\n",
    "        - 파라미터로 norm, stem 사용\n",
    "            - norm : 문장 정규화 여부\n",
    "            - stem : 어간 추출 여부\n",
    "            - 기본값 : False\n",
    "        - Okt.nouns() 텍스트에서 명사만 추출\n",
    "        - Okt.phrases() 텍스트에서 어절 추출\n",
    "        - Okt.pos() 각 품사를 태깅\n",
    "            - 태깅 : 주어진 텍스트를 형태소 단위로 나누는 것을 의미\n",
    "                - 나누어진 형태소와 해당 품사와 함께 리스트화 하는 것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4dee7dc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['교도소', '이야기', '구먼', '솔직하다', '재미', '는', '없다', '평점', '조정']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. 형태소 분석 \n",
    "from konlpy.tag import Okt\n",
    "\n",
    "okt = Okt()  # 객체 생성\n",
    "word_review = okt.morphs(review_text, stem=True)\n",
    "word_review"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5916b23c",
   "metadata": {},
   "source": [
    "### okt 에러 발생 시 java 설치\n",
    "- No JVM shared library file (jvm.dll) found. Try setting up the JAVA_HOME environment variable properly.\n",
    "\n",
    "\n",
    "- 오라클 홈페이지에서 다운로드\n",
    "- 환경변수에 java 패스 등록"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b3a1bbce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['교도소', '이야기', '솔직하다', '재미', '없다', '평점', '조정']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3. stop_words 제거 (불용어, 관용어구)\n",
    "stop_words = ['은','는','이','가','하','아','것','들','의','있','되','수','보','주','등','한','구먼']\n",
    "lis = [token for token in word_review if not token in stop_words]\n",
    "lis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8f37b388",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Tokenizer() 객체를 활용해서 단어와 수자 매핑\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(lis)  # 토큰을 유니크하게 정리해서 각 단어들에 대해 숫자 매핑\n",
    "train_sequences = tokenizer.texts_to_sequences(lis)  # n행 ㅂ열로 변환\n",
    "train_sequences = np.reshape(train_sequences,(1,-1))  # 1행 n열로 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "03b95c21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'교도소': 1, '이야기': 2, '솔직하다': 3, '재미': 4, '없다': 5, '평점': 6, '조정': 7}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4-1. 어휘사전 확인 및 저장\n",
    "word_vocab = tokenizer.word_index\n",
    "word_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "77465d03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3, 4, 5, 6, 7, 0, 0, 0]], dtype=int32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5. 패딩 작업해서 모든 리뷰의 문장 길이를 동일하게 작업\n",
    "MAX_SEQUENCE_LENGTH = 10  # 문장 길이 (상수이므로 대문자)\n",
    "\n",
    "# padding='post' : 문장의 뒷부분을 padding\n",
    "\n",
    "# 패딩 처리\n",
    "train_inputs = pad_sequences(train_sequences, maxlen=MAX_SEQUENCE_LENGTH,\n",
    "                            padding='post')\n",
    "train_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5eb339e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전처리 함수 만들기\n",
    "def preprocessing(review, okt, remove_stopwords = False, stop_words =[]):\n",
    "    #함수인자설명\n",
    "    # review: 전처리할 텍스트\n",
    "    # okt: okt객체를 반복적으로 생성하지 않고 미리 생성 후 인자로 받음\n",
    "    # remove_stopword: 불용어를 제거할지 여부 선택. 기본값 False\n",
    "    # stop_words: 불용어 사전은 사용자가 직접 입력, 기본값 빈 리스트\n",
    "\n",
    "\n",
    "    # 1. 한글 및 공백 제외한 문자 모두 제거\n",
    "    review_text = re.sub('[^가-힣ㄱ-ㅎㅏ-ㅣ\\\\s]','',review)\n",
    "    # review에서 한글및공백을 제외한 문자는 ' '로 치환\n",
    "\n",
    "\n",
    "    # 2. okt 객체를 활용하여 형태소 단어로 나눔\n",
    "    word_review = okt.morphs(review_text,stem=True)\n",
    "\n",
    "\n",
    "    if remove_stopwords:\n",
    "        # 3. 불용어 제거\n",
    "        word_review = [token for token in word_review if not token in stop_words]\n",
    "    return word_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5d0793ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전체 학습 데이터에 대해 전처리\n",
    "okt = Okt()  # 형태소 분석기 객체 생성\n",
    "clean_train_review = []  # 한글 전처리 후 형태소 분석된 리뷰를 저장\n",
    "stop_words=['은','는','이','가','하','아','것','들','의','있','되','수','보','주','등','한','구먼']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c9d1561a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150002, 3)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "398d7fba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['더빙', '진짜', '짜증나다', '목소리'],\n",
       " ['흠', '포스터', '보고', '초딩', '영화', '줄', '오버', '연기', '조차', '가볍다', '않다'],\n",
       " ['너', '무재', '밓었', '다그', '래서', '보다', '추천', '다'],\n",
       " ['교도소', '이야기', '솔직하다', '재미', '없다', '평점', '조정']]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 시간상 일부 데이터만 사용\n",
    "for review in train_data['document'][:10000] :  # 10000개만 가져와서 하기\n",
    "    if type(review) == str : \n",
    "        clean_train_review.append(preprocessing(review,okt,remove_stopwords = True, stop_words =stop_words))\n",
    "    else : \n",
    "        clean_train_review.append([])  # 리뷰가 문자열이 아니면 빈칸으로 놔두기\n",
    "clean_train_review[:4]     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b7c4dbb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트 리뷰도 동일하게 전처리\n",
    "test_data = pd.read_csv('./data/ratings_test.txt', header=0,\n",
    "                        delimiter='\\t', quoting=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "74491eed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['굳다', 'ㅋ'],\n",
       " [],\n",
       " ['뭐', '야', '평점', '나쁘다', '않다', '점', '짜다', '리', '더', '더욱', '아니다'],\n",
       " ['지루하다', '않다', '완전', '막장', '임', '돈', '주다', '보기', '에는']]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_test_review=[]\n",
    "for review in test_data['document'][:10000] :  # 10000개만 가져와서 하기\n",
    "    if type(review) == str : \n",
    "        clean_test_review.append(preprocessing(review,okt,remove_stopwords = True, stop_words =stop_words))\n",
    "    else : \n",
    "        clean_test_review.append([]) # 리뷰가 문자열이 아니면 빈칸으로 놔두기\n",
    "clean_test_review[:4]     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c451774",
   "metadata": {},
   "source": [
    "3. 문자 리뷰를 벡터 데이터로 변환\n",
    "- 라벨 데이터는 긍/부정, 1/0으로 처리되어 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1fe3eb83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습데이터로만 진행\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(clean_train_review)  # 어휘사전 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a9f7caec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습데이터로 생성된 어휘사전을 포함하고 있는 tokenizer\n",
    "train_sequences = tokenizer.texts_to_sequences(clean_train_review)\n",
    "test_sequences = tokenizer.texts_to_sequences(clean_test_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fce49ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vocab = tokenizer.word_index\n",
    "MAX_SEQUENCE_LENGTH = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c2af2c82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 640,    1,  168, 1827,   29,  888,  728,   25], dtype=int32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 학습 데이터 패딩 및 np 데이터 변환\n",
    "train_inputs = pad_sequences(train_sequences,maxlen=MAX_SEQUENCE_LENGTH,\n",
    "                            padding='post')\n",
    "train_labels = np.array(train_data['label'][:10000])\n",
    "train_inputs[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0f883c75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 8)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4ee6cb85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000,)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels.shape\n",
    "\n",
    "# 둘 다 10000개로 개수 동일한지 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8731738a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([656, 339, 112, 357,  16, 862, 114,   0], dtype=int32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 테스트 데이터 패딩 및 np 데이터 변환\n",
    "test_inputs = pad_sequences(test_sequences,maxlen=MAX_SEQUENCE_LENGTH,\n",
    "                            padding='post')\n",
    "test_labels = np.array(test_data['label'][:10000])\n",
    "test_inputs[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e7b38ad8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 8)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f7f51e90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000,)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels.shape\n",
    "\n",
    "# 둘 다 개수 10000개로 동일한지 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b83e798",
   "metadata": {},
   "source": [
    "### 4. 전처리 완료된 데이터 (형태소 분석, 토큰화) numpy 파일로 저장\n",
    "- 어휘사전도 json 파일로 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a11950c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = 'cleandata/'  # .npy 파일 저장 경로지정, # 없으면 생성\n",
    "\n",
    "TRAIN_INPUT_DATA = 'nsmc_train_input.npy'\n",
    "TRAIN_LABEL_DATA = 'nsmc_train_label.npy'\n",
    "\n",
    "TEST_INPUT_DATA = 'nsmc_test_input.npy'\n",
    "TEST_LABEL_DATA = 'nsmc_test_label.npy'\n",
    "\n",
    "DATA_CONFIGS = 'data_configs.json'  # 어휘사전"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a7ca2caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_configs={}\n",
    "data_configs['vocab']=word_vocab  # 어휘사전\n",
    "data_configs['vocab_size']=len(word_vocab)+1  # 특수 vocab 0 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "667ad4dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터를 파일로 저장\n",
    "import os\n",
    "if not os.path.exists(DATA_PATH) :  # 해당 경로가 없으면\n",
    "    os.makedirs(DATA_PATH)  # 생성\n",
    "    \n",
    "# 학습데이터 저장\n",
    "np.save(open(DATA_PATH+TRAIN_INPUT_DATA,'wb'),train_inputs)\n",
    "np.save(open(DATA_PATH+TRAIN_LABEL_DATA,'wb'),train_labels)\n",
    "\n",
    "# 테스트데이터 저장\n",
    "np.save(open(DATA_PATH+TEST_INPUT_DATA,'wb'),test_inputs)\n",
    "np.save(open(DATA_PATH+TEST_LABEL_DATA,'wb'),test_labels)\n",
    "\n",
    "# 단어사전 json으로 저장\n",
    "json.dump(data_configs,open(DATA_PATH+DATA_CONFIGS,'w'),ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f9ee3e",
   "metadata": {},
   "source": [
    "### 단어사전 (어휘사전)\n",
    "- 단어와 매칭되는 임의의 숫자가 key:value 형태로 저장된 파일"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dc5ab7e",
   "metadata": {},
   "source": [
    "### 전처리 완료된 학습/테스트 데이터 활용 모델링 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5bdb2738",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import json\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "495ae370",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 데이터 불러오기\n",
    "DATA_PATH = 'cleandata/'  # .npy파일 저장 경로지정, 없으면 생성\n",
    "TRAIN_INPUT_DATA = 'nsmc_train_input.npy'\n",
    "TRAIN_LABEL_DATA = 'nsmc_train_label.npy'\n",
    "TEST_INPUT_DATA = 'nsmc_test_input.npy'\n",
    "TEST_LABEL_DATA = 'nsmc_test_label.npy'\n",
    "DATA_CONFIGS = 'data_configs.json' #어휘사전\n",
    "DATA_OUT = 'data_out/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9a2c336b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "546a3cc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cleandata/nsmc_train_input.npy'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_PATH+TRAIN_INPUT_DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1ae48b79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([682,  20, 241, 776,   0,   0,   0,   0], dtype=int32)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_input = np.load(open(DATA_PATH+TRAIN_INPUT_DATA,'rb'))\n",
    "train_input[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1a777652",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label = np.load(open(DATA_PATH + TRAIN_LABEL_DATA,'rb'))\n",
    "prepro_configs = json.load(open(DATA_PATH + DATA_CONFIGS,'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "df7872ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000,)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ae0114e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 8)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "35815b64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 640,    1,  168, 1827,   29,  888,  728,   25], dtype=int32)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_input[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a2993fff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: '영화',\n",
       " 2: '하다',\n",
       " 3: '보다',\n",
       " 4: '에',\n",
       " 5: '을',\n",
       " 6: '도',\n",
       " 7: '를',\n",
       " 8: '없다',\n",
       " 9: '이다',\n",
       " 10: '있다',\n",
       " 11: '좋다',\n",
       " 12: '다',\n",
       " 13: '너무',\n",
       " 14: '정말',\n",
       " 15: '재밌다',\n",
       " 16: '만',\n",
       " 17: '적',\n",
       " 18: '같다',\n",
       " 19: '되다',\n",
       " 20: '진짜',\n",
       " 21: '아니다',\n",
       " 22: '으로',\n",
       " 23: '로',\n",
       " 24: '점',\n",
       " 25: '않다',\n",
       " 26: '에서',\n",
       " 27: '나오다',\n",
       " 28: '과',\n",
       " 29: '연기',\n",
       " 30: '만들다',\n",
       " 31: '평점',\n",
       " 32: '최고',\n",
       " 33: '안',\n",
       " 34: '인',\n",
       " 35: '나',\n",
       " 36: '내',\n",
       " 37: '그',\n",
       " 38: '못',\n",
       " 39: '스토리',\n",
       " 40: '사람',\n",
       " 41: '드라마',\n",
       " 42: '왜',\n",
       " 43: '보고',\n",
       " 44: '게',\n",
       " 45: '고',\n",
       " 46: '감동',\n",
       " 47: '생각',\n",
       " 48: '이렇다',\n",
       " 49: '아깝다',\n",
       " 50: '감독',\n",
       " 51: '때',\n",
       " 52: '말',\n",
       " 53: 'ㅋㅋ',\n",
       " 54: '그냥',\n",
       " 55: '시간',\n",
       " 56: '배우',\n",
       " 57: '재미없다',\n",
       " 58: '더',\n",
       " 59: '거',\n",
       " 60: '와',\n",
       " 61: '재미',\n",
       " 62: '요',\n",
       " 63: '내용',\n",
       " 64: '지루하다',\n",
       " 65: '재미있다',\n",
       " 66: '하고',\n",
       " 67: '중',\n",
       " 68: '자다',\n",
       " 69: '네',\n",
       " 70: '주다',\n",
       " 71: '까지',\n",
       " 72: '가다',\n",
       " 73: '뭐',\n",
       " 74: '모르다',\n",
       " 75: '좀',\n",
       " 76: '쓰레기',\n",
       " 77: '작품',\n",
       " 78: '들다',\n",
       " 79: '알다',\n",
       " 80: '지',\n",
       " 81: '하나',\n",
       " 82: '싶다',\n",
       " 83: '사랑',\n",
       " 84: '이건',\n",
       " 85: '그렇다',\n",
       " 86: '볼',\n",
       " 87: 'ㅋ',\n",
       " 88: '정도',\n",
       " 89: '다시',\n",
       " 90: '잘',\n",
       " 91: '이렇게',\n",
       " 92: '마지막',\n",
       " 93: '액션',\n",
       " 94: '저',\n",
       " 95: '개',\n",
       " 96: '기',\n",
       " 97: '주인공',\n",
       " 98: '차다',\n",
       " 99: '걸',\n",
       " 100: '연출',\n",
       " 101: '돈',\n",
       " 102: 'ㅠㅠ',\n",
       " 103: '느낌',\n",
       " 104: '최악',\n",
       " 105: 'ㅡㅡ',\n",
       " 106: '완전',\n",
       " 107: '역시',\n",
       " 108: 'ㅋㅋㅋ',\n",
       " 109: '많다',\n",
       " 110: '지금',\n",
       " 111: '장면',\n",
       " 112: '안되다',\n",
       " 113: '처음',\n",
       " 114: '나다',\n",
       " 115: '오다',\n",
       " 116: '받다',\n",
       " 117: '이야기',\n",
       " 118: '임',\n",
       " 119: '년',\n",
       " 120: '명작',\n",
       " 121: '라',\n",
       " 122: '별로',\n",
       " 123: '별',\n",
       " 124: '남다',\n",
       " 125: '인데',\n",
       " 126: '넘다',\n",
       " 127: '면',\n",
       " 128: '듯',\n",
       " 129: '버리다',\n",
       " 130: '이나',\n",
       " 131: '먹다',\n",
       " 132: '끝',\n",
       " 133: '부터',\n",
       " 134: '일',\n",
       " 135: '많이',\n",
       " 136: '또',\n",
       " 137: '난',\n",
       " 138: '그리고',\n",
       " 139: '괜찮다',\n",
       " 140: '아름답다',\n",
       " 141: '느끼다',\n",
       " 142: '이해',\n",
       " 143: '좋아하다',\n",
       " 144: '서',\n",
       " 145: '라고',\n",
       " 146: '꼭',\n",
       " 147: '인생',\n",
       " 148: '이영화',\n",
       " 149: '결말',\n",
       " 150: '이런',\n",
       " 151: '영',\n",
       " 152: '야',\n",
       " 153: '전',\n",
       " 154: '뻔하다',\n",
       " 155: '소재',\n",
       " 156: '이고',\n",
       " 157: '해주다',\n",
       " 158: '멋지다',\n",
       " 159: '대',\n",
       " 160: '때문',\n",
       " 161: '에게',\n",
       " 162: '한번',\n",
       " 163: '무슨',\n",
       " 164: '남자',\n",
       " 165: '분',\n",
       " 166: '두',\n",
       " 167: '마음',\n",
       " 168: '줄',\n",
       " 169: '엔',\n",
       " 170: '여',\n",
       " 171: '성',\n",
       " 172: '허다',\n",
       " 173: '매력',\n",
       " 174: '알',\n",
       " 175: '어떻다',\n",
       " 176: '되어다',\n",
       " 177: '편',\n",
       " 178: '아쉽다',\n",
       " 179: '기억',\n",
       " 180: '가장',\n",
       " 181: '없이',\n",
       " 182: '랑',\n",
       " 183: '끄다',\n",
       " 184: '가슴',\n",
       " 185: '어리다',\n",
       " 186: '속',\n",
       " 187: '냐',\n",
       " 188: '보기',\n",
       " 189: '지만',\n",
       " 190: '라는',\n",
       " 191: '유치하다',\n",
       " 192: '여자',\n",
       " 193: '죽다',\n",
       " 194: '뿐',\n",
       " 195: '무섭다',\n",
       " 196: '쓰다',\n",
       " 197: 'ㅎㅎ',\n",
       " 198: '모든',\n",
       " 199: '인간',\n",
       " 200: '씨',\n",
       " 201: '짱',\n",
       " 202: '웃기다',\n",
       " 203: '님',\n",
       " 204: '보여주다',\n",
       " 205: '끝나다',\n",
       " 206: '높다',\n",
       " 207: '크다',\n",
       " 208: '애',\n",
       " 209: '솔직하다',\n",
       " 210: '니',\n",
       " 211: '실망',\n",
       " 212: '현실',\n",
       " 213: '맞다',\n",
       " 214: '본',\n",
       " 215: '수준',\n",
       " 216: '개봉',\n",
       " 217: '지다',\n",
       " 218: '번',\n",
       " 219: '전개',\n",
       " 220: '급',\n",
       " 221: '반전',\n",
       " 222: '화',\n",
       " 223: '살다',\n",
       " 224: '인지',\n",
       " 225: '낮다',\n",
       " 226: '늘다',\n",
       " 227: '공감',\n",
       " 228: '캐릭터',\n",
       " 229: '슬프다',\n",
       " 230: '함',\n",
       " 231: '우리',\n",
       " 232: '말다',\n",
       " 233: '자체',\n",
       " 234: '하지만',\n",
       " 235: '찍다',\n",
       " 236: '추천',\n",
       " 237: '인가',\n",
       " 238: '건지다',\n",
       " 239: '코미디',\n",
       " 240: '아이',\n",
       " 241: '짜증나다',\n",
       " 242: '대한',\n",
       " 243: '제',\n",
       " 244: '재다',\n",
       " 245: '제목',\n",
       " 246: '근데',\n",
       " 247: 'ㅋㅋㅋㅋ',\n",
       " 248: '다른',\n",
       " 249: '움',\n",
       " 250: '표현',\n",
       " 251: '뭔가',\n",
       " 252: '돼다',\n",
       " 253: '계속',\n",
       " 254: '음악',\n",
       " 255: '대단하다',\n",
       " 256: '전혀',\n",
       " 257: '미치다',\n",
       " 258: '처럼',\n",
       " 259: '이라',\n",
       " 260: '연기력',\n",
       " 261: '눈',\n",
       " 262: '눈물',\n",
       " 263: '기대하다',\n",
       " 264: '이제',\n",
       " 265: '여운',\n",
       " 266: '내다',\n",
       " 267: '에는',\n",
       " 268: '이상',\n",
       " 269: '연',\n",
       " 270: '중간',\n",
       " 271: '일본',\n",
       " 272: '빠지다',\n",
       " 273: '몰입',\n",
       " 274: '야하다',\n",
       " 275: '기분',\n",
       " 276: '이란',\n",
       " 277: '시리즈',\n",
       " 278: '뭔',\n",
       " 279: '이쁘다',\n",
       " 280: '욕',\n",
       " 281: '가족',\n",
       " 282: '작가',\n",
       " 283: '믿다',\n",
       " 284: '한국',\n",
       " 285: 'ㅠ',\n",
       " 286: '시키다',\n",
       " 287: '이라는',\n",
       " 288: '잔잔하다',\n",
       " 289: '아주',\n",
       " 290: '이유',\n",
       " 291: '굿',\n",
       " 292: '보이다',\n",
       " 293: '모습',\n",
       " 294: '울다',\n",
       " 295: '부분',\n",
       " 296: '모두',\n",
       " 297: '걍',\n",
       " 298: '이네',\n",
       " 299: '짜다',\n",
       " 300: '밖에',\n",
       " 301: '내내',\n",
       " 302: '영상',\n",
       " 303: '원작',\n",
       " 304: '웃다',\n",
       " 305: 'ㅜㅜ',\n",
       " 306: '떨어지다',\n",
       " 307: '잼',\n",
       " 308: '잇다',\n",
       " 309: '절대',\n",
       " 310: '나름',\n",
       " 311: '아직도',\n",
       " 312: '깊다',\n",
       " 313: '기대',\n",
       " 314: '진심',\n",
       " 315: '애니',\n",
       " 316: '그래도',\n",
       " 317: '작',\n",
       " 318: '감',\n",
       " 319: '위',\n",
       " 320: '긴장감',\n",
       " 321: '건',\n",
       " 322: '후',\n",
       " 323: '당시',\n",
       " 324: '점수',\n",
       " 325: '점도',\n",
       " 326: '수작',\n",
       " 327: '이랑',\n",
       " 328: '오랜',\n",
       " 329: '막장',\n",
       " 330: '귀엽다',\n",
       " 331: '자',\n",
       " 332: '치다',\n",
       " 333: '극장',\n",
       " 334: '력',\n",
       " 335: '딱',\n",
       " 336: '스릴러',\n",
       " 337: '찾다',\n",
       " 338: '느껴지다',\n",
       " 339: '몇',\n",
       " 340: '년대',\n",
       " 341: '이라고',\n",
       " 342: '개인',\n",
       " 343: '요즘',\n",
       " 344: '보지',\n",
       " 345: '물',\n",
       " 346: '시',\n",
       " 347: '라면',\n",
       " 348: '노잼',\n",
       " 349: '조금',\n",
       " 350: '한테',\n",
       " 351: '인상',\n",
       " 352: '따뜻하다',\n",
       " 353: '삶',\n",
       " 354: '특히',\n",
       " 355: '대박',\n",
       " 356: '포스터',\n",
       " 357: '졸작',\n",
       " 358: '문제',\n",
       " 359: '어',\n",
       " 360: '친구',\n",
       " 361: '이딴',\n",
       " 362: '써다',\n",
       " 363: '접',\n",
       " 364: '너',\n",
       " 365: '놈',\n",
       " 366: '추억',\n",
       " 367: '노래',\n",
       " 368: '아프다',\n",
       " 369: '세',\n",
       " 370: '제대로',\n",
       " 371: '신선하다',\n",
       " 372: '한국영',\n",
       " 373: '용',\n",
       " 374: '알바',\n",
       " 375: '결국',\n",
       " 376: '멋있다',\n",
       " 377: 'ㅎ',\n",
       " 378: '식',\n",
       " 379: '나가다',\n",
       " 380: '에도',\n",
       " 381: '스럽다',\n",
       " 382: '충분하다',\n",
       " 383: '자신',\n",
       " 384: '배경',\n",
       " 385: '예쁘다',\n",
       " 386: '앞',\n",
       " 387: '안타깝다',\n",
       " 388: '빼다',\n",
       " 389: '공포',\n",
       " 390: '보단',\n",
       " 391: '초반',\n",
       " 392: '설정',\n",
       " 393: '티비',\n",
       " 394: '해보다',\n",
       " 395: '공포영화',\n",
       " 396: '우리나라',\n",
       " 397: '이상하다',\n",
       " 398: '죽이다',\n",
       " 399: '대사',\n",
       " 400: '이지',\n",
       " 401: '필요없다',\n",
       " 402: '반',\n",
       " 403: '데',\n",
       " 404: '극',\n",
       " 405: '정신',\n",
       " 406: '제일',\n",
       " 407: '웃음',\n",
       " 408: '남',\n",
       " 409: '시나리오',\n",
       " 410: '가지',\n",
       " 411: '의미',\n",
       " 412: '캐스팅',\n",
       " 413: '더럽다',\n",
       " 414: '훌륭하다',\n",
       " 415: '세상',\n",
       " 416: '장난',\n",
       " 417: '함께',\n",
       " 418: '무엇',\n",
       " 419: '대해',\n",
       " 420: '이야',\n",
       " 421: '어설프다',\n",
       " 422: '뭘',\n",
       " 423: '아무',\n",
       " 424: '따다',\n",
       " 425: '기도',\n",
       " 426: '엄청',\n",
       " 427: '팬',\n",
       " 428: '마다',\n",
       " 429: '원',\n",
       " 430: '시작',\n",
       " 431: '도대체',\n",
       " 432: '나이',\n",
       " 433: '사실',\n",
       " 434: '위해',\n",
       " 435: '힘들다',\n",
       " 436: '완벽하다',\n",
       " 437: '음',\n",
       " 438: '전쟁',\n",
       " 439: '책',\n",
       " 440: '영화로',\n",
       " 441: '최고다',\n",
       " 442: '이지만',\n",
       " 443: '씬',\n",
       " 444: '배우다',\n",
       " 445: '대다',\n",
       " 446: '쓸다',\n",
       " 447: '질',\n",
       " 448: '류',\n",
       " 449: '같이',\n",
       " 450: '발연기',\n",
       " 451: '평가',\n",
       " 452: '두다',\n",
       " 453: '맘',\n",
       " 454: '그저',\n",
       " 455: '그대로',\n",
       " 456: '어이없다',\n",
       " 457: '미국',\n",
       " 458: '해',\n",
       " 459: '아직',\n",
       " 460: '웃기',\n",
       " 461: '엄마',\n",
       " 462: '부족하다',\n",
       " 463: '기다',\n",
       " 464: '이후',\n",
       " 465: '영화관',\n",
       " 466: '얼굴',\n",
       " 467: '차라리',\n",
       " 468: '낫다',\n",
       " 469: '몰입도',\n",
       " 470: '한마디',\n",
       " 471: '답답하다',\n",
       " 472: '비다',\n",
       " 473: '첨',\n",
       " 474: '중국',\n",
       " 475: '봄',\n",
       " 476: '엉',\n",
       " 477: '어색하다',\n",
       " 478: '실화',\n",
       " 479: '간',\n",
       " 480: '오',\n",
       " 481: '잊다',\n",
       " 482: '매우',\n",
       " 483: '로맨스',\n",
       " 484: '놓다',\n",
       " 485: '멀다',\n",
       " 486: '오늘',\n",
       " 487: '쯤',\n",
       " 488: '후회',\n",
       " 489: '역사',\n",
       " 490: '시대',\n",
       " 491: '그렇게',\n",
       " 492: '놀라다',\n",
       " 493: '살리다',\n",
       " 494: '갈수록',\n",
       " 495: '어디',\n",
       " 496: '새롭다',\n",
       " 497: '어느',\n",
       " 498: '코믹',\n",
       " 499: '소리',\n",
       " 500: '분위기',\n",
       " 501: '이라도',\n",
       " 502: '관객',\n",
       " 503: '상',\n",
       " 504: '충격',\n",
       " 505: '집',\n",
       " 506: '서다',\n",
       " 507: '생기다',\n",
       " 508: '얼마나',\n",
       " 509: '즐겁다',\n",
       " 510: '망하다',\n",
       " 511: '애니메이션',\n",
       " 512: '아무리',\n",
       " 513: '장르',\n",
       " 514: '출연',\n",
       " 515: '총',\n",
       " 516: '훨씬',\n",
       " 517: '분들',\n",
       " 518: '명',\n",
       " 519: '그리다',\n",
       " 520: '심하다',\n",
       " 521: '읽다',\n",
       " 522: '제발',\n",
       " 523: '날',\n",
       " 524: '여배우',\n",
       " 525: '떠나다',\n",
       " 526: '누가',\n",
       " 527: '여기',\n",
       " 528: '생각나다',\n",
       " 529: '영화인',\n",
       " 530: '만큼',\n",
       " 531: '진부하다',\n",
       " 532: '작다',\n",
       " 533: '회',\n",
       " 534: '건가',\n",
       " 535: '밉다',\n",
       " 536: '유쾌하다',\n",
       " 537: '당하다',\n",
       " 538: '구성',\n",
       " 539: '준',\n",
       " 540: '누구',\n",
       " 541: '해도',\n",
       " 542: '꽤',\n",
       " 543: '코',\n",
       " 544: '킬링타임',\n",
       " 545: '머',\n",
       " 546: '어울리다',\n",
       " 547: '그만',\n",
       " 548: '다르다',\n",
       " 549: '싫다',\n",
       " 550: '시절',\n",
       " 551: '부',\n",
       " 552: '개연',\n",
       " 553: '지루함',\n",
       " 554: '돌리다',\n",
       " 555: '엔딩',\n",
       " 556: '드리다',\n",
       " 557: '그나마',\n",
       " 558: '소름',\n",
       " 559: '억',\n",
       " 560: '이르다',\n",
       " 561: '구',\n",
       " 562: '짜증',\n",
       " 563: '흥행',\n",
       " 564: '전부',\n",
       " 565: '점점',\n",
       " 566: '옛날',\n",
       " 567: '나쁘다',\n",
       " 568: '니까',\n",
       " 569: '순간',\n",
       " 570: '어렵다',\n",
       " 571: '스릴',\n",
       " 572: '오글거리다',\n",
       " 573: '편이',\n",
       " 574: '비디오',\n",
       " 575: '탄탄하다',\n",
       " 576: '만화',\n",
       " 577: '전체',\n",
       " 578: '간만',\n",
       " 579: '여주',\n",
       " 580: '화려하다',\n",
       " 581: '이리',\n",
       " 582: '대체',\n",
       " 583: '소설',\n",
       " 584: '감정',\n",
       " 585: '다큐',\n",
       " 586: '상황',\n",
       " 587: '방송',\n",
       " 588: '년도',\n",
       " 589: '든',\n",
       " 590: '따르다',\n",
       " 591: '필요하다',\n",
       " 592: '다운',\n",
       " 593: '터지다',\n",
       " 594: '머리',\n",
       " 595: '자기',\n",
       " 596: '만점',\n",
       " 597: '예술',\n",
       " 598: '돋다',\n",
       " 599: '좀비',\n",
       " 600: '주제',\n",
       " 601: '그래서',\n",
       " 602: '낭비',\n",
       " 603: '행복하다',\n",
       " 604: '너무나',\n",
       " 605: '년전',\n",
       " 606: '살',\n",
       " 607: '잔인하다',\n",
       " 608: '상당하다',\n",
       " 609: '판',\n",
       " 610: '진',\n",
       " 611: '바라다',\n",
       " 612: '약간',\n",
       " 613: '들이다',\n",
       " 614: '엄청나다',\n",
       " 615: '쉬다',\n",
       " 616: '울',\n",
       " 617: '달다',\n",
       " 618: '거의',\n",
       " 619: '발',\n",
       " 620: '그것',\n",
       " 621: '뻔',\n",
       " 622: '뒤',\n",
       " 623: '에선',\n",
       " 624: '언제',\n",
       " 625: '비슷하다',\n",
       " 626: '강추',\n",
       " 627: '답',\n",
       " 628: '한편',\n",
       " 629: '피',\n",
       " 630: '네이버',\n",
       " 631: '싸우다',\n",
       " 632: '인물',\n",
       " 633: 'ㅡ',\n",
       " 634: '감사하다',\n",
       " 635: '갑자기',\n",
       " 636: '참고',\n",
       " 637: '존재',\n",
       " 638: '집중',\n",
       " 639: '시즌',\n",
       " 640: '초딩',\n",
       " 641: '걸리다',\n",
       " 642: '성룡',\n",
       " 643: '순수하다',\n",
       " 644: '화가',\n",
       " 645: '사랑스럽다',\n",
       " 646: '라니',\n",
       " 647: '어디서',\n",
       " 648: '이름',\n",
       " 649: '얘기',\n",
       " 650: '사회',\n",
       " 651: '키',\n",
       " 652: '그런',\n",
       " 653: '복수',\n",
       " 654: '풀다',\n",
       " 655: '존나',\n",
       " 656: '걸작',\n",
       " 657: '타다',\n",
       " 658: '죠',\n",
       " 659: '선',\n",
       " 660: '안보',\n",
       " 661: '주연',\n",
       " 662: '비교',\n",
       " 663: '맛',\n",
       " 664: '적다',\n",
       " 665: '빨리',\n",
       " 666: '산',\n",
       " 667: '라서',\n",
       " 668: '또한',\n",
       " 669: '아들',\n",
       " 670: '죽',\n",
       " 671: '비',\n",
       " 672: '극장판',\n",
       " 673: '당신',\n",
       " 674: '말고',\n",
       " 675: '흐르다',\n",
       " 676: '며',\n",
       " 677: '미화',\n",
       " 678: '전작',\n",
       " 679: '점주',\n",
       " 680: '아버지',\n",
       " 681: '불편하다',\n",
       " 682: '더빙',\n",
       " 683: '흠',\n",
       " 684: '다니다',\n",
       " 685: '에서도',\n",
       " 686: '완성',\n",
       " 687: '힘드다',\n",
       " 688: '래',\n",
       " 689: '씩',\n",
       " 690: '그러나',\n",
       " 691: '끌다',\n",
       " 692: '사건',\n",
       " 693: '보내다',\n",
       " 694: '확실하다',\n",
       " 695: '단',\n",
       " 696: '곳',\n",
       " 697: '만의',\n",
       " 698: '상미',\n",
       " 699: '선택',\n",
       " 700: '화면',\n",
       " 701: '동안',\n",
       " 702: '원래',\n",
       " 703: '모',\n",
       " 704: '감성',\n",
       " 705: 'ㅉㅉ',\n",
       " 706: '만들어지다',\n",
       " 707: '왠만하다',\n",
       " 708: '화이팅',\n",
       " 709: '그녀',\n",
       " 710: '게임',\n",
       " 711: '히',\n",
       " 712: '가보다',\n",
       " 713: '장',\n",
       " 714: '휴',\n",
       " 715: '질질',\n",
       " 716: '평생',\n",
       " 717: '조',\n",
       " 718: '최근',\n",
       " 719: '제작',\n",
       " 720: '맨',\n",
       " 721: '궁금하다',\n",
       " 722: '으로도',\n",
       " 723: '재',\n",
       " 724: '무조건',\n",
       " 725: '만나다',\n",
       " 726: '몇번',\n",
       " 727: '졸라',\n",
       " 728: '가볍다',\n",
       " 729: '막',\n",
       " 730: '라도',\n",
       " 731: '혼자',\n",
       " 732: '노력',\n",
       " 733: '예전',\n",
       " 734: '엉망',\n",
       " 735: '뜨다',\n",
       " 736: '판타지',\n",
       " 737: '허무하다',\n",
       " 738: '꿈',\n",
       " 739: '비추다',\n",
       " 740: '흥미진진',\n",
       " 741: '형',\n",
       " 742: '물론',\n",
       " 743: '괜히',\n",
       " 744: '거리',\n",
       " 745: '남기다',\n",
       " 746: '억지',\n",
       " 747: '성하다',\n",
       " 748: '요소',\n",
       " 749: '이에요',\n",
       " 750: '똑같다',\n",
       " 751: '평',\n",
       " 752: '먼저',\n",
       " 753: '소중하다',\n",
       " 754: '힘',\n",
       " 755: '취향',\n",
       " 756: 'ㅇ',\n",
       " 757: '간다',\n",
       " 758: '살인',\n",
       " 759: '시청률',\n",
       " 760: '에요',\n",
       " 761: '술',\n",
       " 762: '케이블',\n",
       " 763: '세계',\n",
       " 764: '느와르',\n",
       " 765: '거기',\n",
       " 766: '끼다',\n",
       " 767: '만으로도',\n",
       " 768: '상영',\n",
       " 769: '그게',\n",
       " 770: '만하',\n",
       " 771: '지나다',\n",
       " 772: '소녀',\n",
       " 773: '담다',\n",
       " 774: '죄',\n",
       " 775: '찾아보다',\n",
       " 776: '목소리',\n",
       " 777: '뛰어나다',\n",
       " 778: '예요',\n",
       " 779: '억지스럽다',\n",
       " 780: '위대하다',\n",
       " 781: '흥미',\n",
       " 782: '특유',\n",
       " 783: '자극',\n",
       " 784: '재밋',\n",
       " 785: '돌아가다',\n",
       " 786: '강하다',\n",
       " 787: '화보',\n",
       " 788: '똥',\n",
       " 789: '평론가',\n",
       " 790: '일이',\n",
       " 791: '뭐라다',\n",
       " 792: '약하다',\n",
       " 793: '보다는',\n",
       " 794: '거지',\n",
       " 795: '각본',\n",
       " 796: '스타일',\n",
       " 797: '배',\n",
       " 798: '진정하다',\n",
       " 799: '기다리다',\n",
       " 800: '항상',\n",
       " 801: '다루다',\n",
       " 802: '신',\n",
       " 803: '사',\n",
       " 804: '터',\n",
       " 805: '동화',\n",
       " 806: '들어가다',\n",
       " 807: '헐다',\n",
       " 808: '나르다',\n",
       " 809: '순',\n",
       " 810: '굉장하다',\n",
       " 811: '언',\n",
       " 812: '그때',\n",
       " 813: '귀신',\n",
       " 814: '묻다',\n",
       " 815: '드',\n",
       " 816: 'ㅜ',\n",
       " 817: '굳이',\n",
       " 818: '몰다',\n",
       " 819: '한심하다',\n",
       " 820: '아빠',\n",
       " 821: '실제',\n",
       " 822: '제작비',\n",
       " 823: '아저씨',\n",
       " 824: '삼류',\n",
       " 825: '통해',\n",
       " 826: '상처',\n",
       " 827: '짓',\n",
       " 828: '수가',\n",
       " 829: '팔',\n",
       " 830: '군',\n",
       " 831: '황당하다',\n",
       " 832: '꿀잼',\n",
       " 833: '흔하다',\n",
       " 834: '역대',\n",
       " 835: '편집',\n",
       " 836: '이기다',\n",
       " 837: '귀',\n",
       " 838: '어른',\n",
       " 839: '오빠',\n",
       " 840: '예상',\n",
       " 841: '몸',\n",
       " 842: '전편',\n",
       " 843: '얻다',\n",
       " 844: '햇',\n",
       " 845: '열',\n",
       " 846: '반개',\n",
       " 847: '멜로',\n",
       " 848: '손',\n",
       " 849: '안나',\n",
       " 850: '방법',\n",
       " 851: '소',\n",
       " 852: '이라니',\n",
       " 853: '인거',\n",
       " 854: '현',\n",
       " 855: '잡다',\n",
       " 856: '나라',\n",
       " 857: '교훈',\n",
       " 858: '후반',\n",
       " 859: '쩔다',\n",
       " 860: '흥미롭다',\n",
       " 861: '예산',\n",
       " 862: '넘치다',\n",
       " 863: '필요',\n",
       " 864: '일단',\n",
       " 865: '액션영화',\n",
       " 866: '빠져들다',\n",
       " 867: '짧다',\n",
       " 868: '부르다',\n",
       " 869: '암',\n",
       " 870: '개다',\n",
       " 871: '불쾌하다',\n",
       " 872: '이번',\n",
       " 873: '메세지',\n",
       " 874: '개그',\n",
       " 875: '즐기다',\n",
       " 876: '다음',\n",
       " 877: '이하',\n",
       " 878: '께',\n",
       " 879: '티',\n",
       " 880: '일어나다',\n",
       " 881: '새끼',\n",
       " 882: '하하',\n",
       " 883: '학교',\n",
       " 884: '안좋다',\n",
       " 885: '도저히',\n",
       " 886: '밑',\n",
       " 887: '글',\n",
       " 888: '조차',\n",
       " 889: '엿',\n",
       " 890: '노',\n",
       " 891: '이기',\n",
       " 892: '중반',\n",
       " 893: '온',\n",
       " 894: '깊이',\n",
       " 895: '바로',\n",
       " 896: '차',\n",
       " 897: '빨',\n",
       " 898: '계',\n",
       " 899: '이냐',\n",
       " 900: '나서다',\n",
       " 901: '생',\n",
       " 902: '만이',\n",
       " 903: '훈훈하다',\n",
       " 904: '범죄',\n",
       " 905: '실망하다',\n",
       " 906: '걸다',\n",
       " 907: '대작',\n",
       " 908: '땐',\n",
       " 909: '살아가다',\n",
       " 910: '의도',\n",
       " 911: '망치다',\n",
       " 912: '잃다',\n",
       " 913: '열심히',\n",
       " 914: '역겹다',\n",
       " 915: '다만',\n",
       " 916: '까진',\n",
       " 917: '불쌍하다',\n",
       " 918: '맞추다',\n",
       " 919: '기억나다',\n",
       " 920: '철학',\n",
       " 921: '특별하다',\n",
       " 922: '시도',\n",
       " 923: '여성',\n",
       " 924: '으로는',\n",
       " 925: '어이',\n",
       " 926: '끝내다',\n",
       " 927: '이며',\n",
       " 928: '결혼',\n",
       " 929: '독특하다',\n",
       " 930: '참신하다',\n",
       " 931: '전설',\n",
       " 932: '결과',\n",
       " 933: '공',\n",
       " 934: '돋보이다',\n",
       " 935: '떼다',\n",
       " 936: '단순하다',\n",
       " 937: '심심하다',\n",
       " 938: '삼',\n",
       " 939: 'ㅋㅋㅋㅋㅋ',\n",
       " 940: '연기자',\n",
       " 941: '왠지',\n",
       " 942: '치고',\n",
       " 943: '지키다',\n",
       " 944: '청춘',\n",
       " 945: '으',\n",
       " 946: '댓글',\n",
       " 947: '란',\n",
       " 948: '따라가다',\n",
       " 949: '가치',\n",
       " 950: '어쩔',\n",
       " 951: '성도',\n",
       " 952: '인하다',\n",
       " 953: '감다',\n",
       " 954: '둘',\n",
       " 955: '랄',\n",
       " 956: '리얼',\n",
       " 957: '나중',\n",
       " 958: '견자단',\n",
       " 959: '바꾸다',\n",
       " 960: '스러운',\n",
       " 961: '자식',\n",
       " 962: '미안하다',\n",
       " 963: '희망',\n",
       " 964: '우울하다',\n",
       " 965: '종교',\n",
       " 966: '에겐',\n",
       " 967: '등장',\n",
       " 968: '게이',\n",
       " 969: '즈',\n",
       " 970: '프랑스',\n",
       " 971: '따위',\n",
       " 972: '채널',\n",
       " 973: '짐',\n",
       " 974: '기적',\n",
       " 975: '현재',\n",
       " 976: '잊혀지다',\n",
       " 977: '가지다',\n",
       " 978: '줄거리',\n",
       " 979: '으리',\n",
       " 980: '당',\n",
       " 981: '촬영',\n",
       " 982: '마르다',\n",
       " 983: '심리',\n",
       " 984: '심',\n",
       " 985: '그닥',\n",
       " 986: '더욱',\n",
       " 987: '포기',\n",
       " 988: '바뀌다',\n",
       " 989: '마무리',\n",
       " 990: '너무나도',\n",
       " 991: '볼때',\n",
       " 992: '올',\n",
       " 993: '표절',\n",
       " 994: '바',\n",
       " 995: '가면',\n",
       " 996: '악역',\n",
       " 997: '진정',\n",
       " 998: '가요',\n",
       " 999: '실감',\n",
       " 1000: '지난',\n",
       " ...}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 숫자에 대응되는 단어 확인하기 위해 prepro_configs의 key, value 뒤집기\n",
    "tmp_dict = dict(map(reversed,prepro_configs['vocab'].items()))\n",
    "tmp_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5b14b588",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "더빙\n",
      "진짜\n",
      "짜증나다\n",
      "목소리\n"
     ]
    }
   ],
   "source": [
    "for vl in train_input[0][:4] : \n",
    "    print(tmp_dict[vl])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "98d55cd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "초딩\n",
      "영화\n",
      "줄\n",
      "오버\n",
      "연기\n",
      "조차\n",
      "가볍다\n",
      "않다\n"
     ]
    }
   ],
   "source": [
    "for vl in train_input[1] : \n",
    "    print(tmp_dict[vl])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9534c9e",
   "metadata": {},
   "source": [
    "### 모델 구성\n",
    "- tensorflow.keras.Model 상속 받아서\n",
    "    - 사용자 정의 모델 클래스 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2a92c347",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['vocab', 'vocab_size'])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prepro_configs.keys() # 어휘사전 load한 dict 변수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8826bccd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12351"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = prepro_configs['vocab_size']  # 총 단어수\n",
    "embbeding_size= 128\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d8e311c",
   "metadata": {},
   "source": [
    "### CNN 모델 구성\n",
    "- 이미지 사용 : Conv2D - 2차원 이미지를 그대로 학습\n",
    "- 문장과 같은 1차원의 sequential 데이터 cnn 적용할 때 : Conv1D 층\n",
    "- Embedding 층 사용 (밀집벡터 생성)\n",
    "- MaxPooling1D : 입력벡터에서 특정 구간마다 최대값을 골라 벡터 구성\n",
    "- GlobalMaxPooling1D : 여러 개의 벡터 정보 중 가장 큰 벡터를 골라서 반환\n",
    "    - 필터가 내놓은 특성맵 중에 제일 큰 특성맵 하나만 고름"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "656d2b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Flatten,Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "be4da434",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size,embbeding_size))\n",
    "model.add(tf.keras.layers.Conv1D(100,5,activation='relu'))\n",
    "model.add(tf.keras.layers.GlobalMaxPooling1D())\n",
    "model.add(tf.keras.layers.Dropout(rate=0.2))\n",
    "model.add(tf.keras.layers.Dense(250, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(1,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "38299d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "             loss='binary_crossentropy',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4b0ddb0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, None, 128)         1580928   \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, None, 100)         64100     \n",
      "                                                                 \n",
      " global_max_pooling1d (Globa  (None, 100)              0         \n",
      " lMaxPooling1D)                                                  \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 100)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 250)               25250     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 251       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,670,529\n",
      "Trainable params: 1,670,529\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "037fdc12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 8)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a7253ac5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000,)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ede281e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 512\n",
    "NUM_EPOCHS = 10\n",
    "VALID_SPLIT = 0.1\n",
    "MAX_LEN = train_input.shape[1]\n",
    "model_name = 'naver'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d77c2bc9",
   "metadata": {},
   "source": [
    "### EarlyStopping(min_delta=n)\n",
    "- 개선된 것으로 간주하기 위한 최소한의 변화량\n",
    "- ex. min_delta값이 0.01dlrh 50 epoch에 정확도가 0.86 라고 할 때, 51 epoch에서 정확도가 0.8652로 높아졌다.\n",
    "- 이는 0.0052의 개선이 있었지만, min_delta값인 0.01에 미치지 못하기 때문에 개선되었다고 보지 않고 patience를 확인한 후에 조기종료 할 수도 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f081a356",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 검증 정확도를 통한 EarlyStopping 기능 및 모델 저장 방식 지정\n",
    "earlystop_callback = EarlyStopping(monitor='val_acc', \n",
    "                                   min_delta=0.0001,\n",
    "                                   patience=2)\n",
    "\n",
    "checkpoint_path = DATA_OUT + model_name +'weights.h5'\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5f6fe3ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data_out/naverweights.h5'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d7df167f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_out -- Folder already exists \n",
      "\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists(checkpoint_dir):\n",
    "    print(\"{} -- Folder already exists \\n\".format(checkpoint_dir))\n",
    "else:\n",
    "    os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "    print(\"{} -- Folder create complete \\n\".format(checkpoint_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "44f4230b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cp_callback = ModelCheckpoint(\n",
    "    checkpoint_path, monitor = 'val_acc', verbose=1, save_best_only = True,\n",
    "    save_weights_only=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "fa5bd0ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.6876 - accuracy: 0.5639WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "18/18 [==============================] - 7s 53ms/step - loss: 0.6876 - accuracy: 0.5639 - val_loss: 0.6711 - val_accuracy: 0.7030\n",
      "Epoch 2/10\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.5714 - accuracy: 0.7894WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.5714 - accuracy: 0.7894 - val_loss: 0.5245 - val_accuracy: 0.7490\n",
      "Epoch 3/10\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 0.3305 - accuracy: 0.8673WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.3268 - accuracy: 0.8672 - val_loss: 0.5540 - val_accuracy: 0.7450\n",
      "Epoch 4/10\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 0.1926 - accuracy: 0.9327WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.1925 - accuracy: 0.9313 - val_loss: 0.6050 - val_accuracy: 0.7450\n",
      "Epoch 5/10\n",
      "12/18 [===================>..........] - ETA: 0s - loss: 0.1212 - accuracy: 0.9627WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.1169 - accuracy: 0.9626 - val_loss: 0.6998 - val_accuracy: 0.7440\n",
      "Epoch 6/10\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 0.0709 - accuracy: 0.9781WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0738 - accuracy: 0.9767 - val_loss: 0.8078 - val_accuracy: 0.7470\n",
      "Epoch 7/10\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 0.0527 - accuracy: 0.9841WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0515 - accuracy: 0.9833 - val_loss: 0.9195 - val_accuracy: 0.7400\n",
      "Epoch 8/10\n",
      "12/18 [===================>..........] - ETA: 0s - loss: 0.0336 - accuracy: 0.9899WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0351 - accuracy: 0.9892 - val_loss: 1.0173 - val_accuracy: 0.7380\n",
      "Epoch 9/10\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 0.0256 - accuracy: 0.9911WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0273 - accuracy: 0.9907 - val_loss: 1.1057 - val_accuracy: 0.7420\n",
      "Epoch 10/10\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 0.0210 - accuracy: 0.9932WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0202 - accuracy: 0.9929 - val_loss: 1.1919 - val_accuracy: 0.7340\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_input,\n",
    "                    train_label,\n",
    "                    batch_size=BATCH_SIZE,\n",
    "                    epochs = NUM_EPOCHS,\n",
    "                    validation_split=VALID_SPLIT,  # 검증 비율 전달\n",
    "                    callbacks=[earlystop_callback,cp_callback]\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "080bc0c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_INPUT_DATA = 'nsmc_test_input.npy'\n",
    "TEST_LABEL_DATA = 'nsmc_test_label.npy'\n",
    "\n",
    "test_input = np.load(open(DATA_PATH +TEST_INPUT_DATA,'rb' ))\n",
    "test_label = np.load(open(DATA_PATH +TEST_LABEL_DATA,'rb' ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "83b3fad1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000,)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_input.shape\n",
    "test_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "79ce2a1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 1.1657 - accuracy: 0.7407\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.165748953819275, 0.7407000064849854]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_input, test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "6ebced3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최종 모델 저장\n",
    "model.save('review.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f6dc82",
   "metadata": {},
   "source": [
    "### 예측하기\n",
    "- 저장된 모델을 활용해서 예측 프로세스 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "5e57dd0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import json\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e93072cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 불러오기\n",
    "model = tf.keras.models.load_model('review.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e9a65a",
   "metadata": {},
   "source": [
    "### 학습 후 완성된 모델을 저장했음\n",
    "- 이 모델을 이용해 새로 입력되는 문장에 대해 긍/부정 판단\n",
    "- **새로 입력되는 문장도 학습데이터와 동일하게 전처리 되어야 함**\n",
    "    - 학습데이터에서 사용한 어휘사전을 그대로 사용해야 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "86af0b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Okt\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "okt = Okt()\n",
    "tokenizer  = Tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "29ec37b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 시 사용한 어휘사전 불러오기\n",
    "DATA_CONFIGS = 'cleandata/data_configs.json'\n",
    "prepro_configs = json.load(open(DATA_CONFIGS, 'r'))\n",
    "word_vocab = prepro_configs['vocab']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "933d2c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer 구성 - 학습 시 생성해 놓은 어휘사전을 이용해서 재구성\n",
    "tokenizer.fit_on_texts(word_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "9d6b978e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "감성 분석할 문장을 입력해 주세요 : 너무 재밌어요!\n",
      "['너무', '재밌다']\n",
      "[[[13]\n",
      "  [15]\n",
      "  [ 0]\n",
      "  [ 0]\n",
      "  [ 0]\n",
      "  [ 0]\n",
      "  [ 0]\n",
      "  [ 0]]]\n",
      "[[0.98566794]]\n",
      "98.57%확률로 긍정 리뷰 입니다.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 나머지 전처리 진행\n",
    "MAX_LENGTH = 8\n",
    "sentence = input('감성 분석할 문장을 입력해 주세요 : ')\n",
    "\n",
    "# 새로 입력된 문장을 전처리\n",
    "sentence = re.sub(r'[^ㄱ-ㅎㅏ-ㅣ가-힣\\\\s ]','', sentence)\n",
    "stopwords = ['은','는','이','가','하','아','것','들','의','있','되','수','보','주','등','한'] # 불용어 추가할 것이 있으면 이곳에 추가\n",
    "sentence = okt.morphs(sentence, stem=True)  # 형태소 분석 토큰화\n",
    "sentence = [word for word in sentence if not word in stopwords]  # 불용어 제거\n",
    "print(sentence)\n",
    "\n",
    "vector = tokenizer.texts_to_sequences(sentence)\n",
    "pad_new = pad_sequences([vector],maxlen=MAX_LENGTH,padding='post')\n",
    "print(pad_new)\n",
    "model=tf.keras.models.load_model('review.h5')\n",
    "pred = model.predict(pad_new)\n",
    "print(pred)\n",
    "pred=float(pred)\n",
    "\n",
    "if(pred>0.5) :\n",
    "    print(\"{:.2f}%확률로 긍정 리뷰 입니다.\\n\".format(pred*100))\n",
    "else : \n",
    "    print(\"{:.2f}%확률로 부정 리뷰 입니다.\\n\".format((1-pred)*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
