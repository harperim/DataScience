{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "944cfb63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d380d35a",
   "metadata": {},
   "source": [
    "### opencv를 활용한 객체 검출\n",
    "- opencv 내에는 yolov3의 객체를 라이브러리로 제공\n",
    "- YOLO : You Only Look Once\n",
    "    - 한 개의 네트워크에서 탐지를 원하는 물체의 영역(bounding box)과 이름을 표시함\n",
    "\n",
    "\n",
    "1. YOLO 기본 구조\n",
    "- YOLO3-416 : 416x416 이미지를 input으로 하는 모델을 의미\n",
    "- 총 3개의 output layer를 갖고 있음 (82, 94, 106 레이어)\n",
    "- 피처 정보들을 조합하여 찾고자 하는 객체 위치를 찾는다.\n",
    "- 입력된 이미지를 일정 분할로 그리드한 다음 (그리드 기준 분할)\n",
    "    - 잘게 쪼개진 이미지를 신경망을 통과시켜서 클래스 예측\n",
    "    - 객체 검출만 진행하는 알고리즘이고 회귀문제로 정의하고 있다고 발표함\n",
    "        - 단점 : 작은 물체에 대한 검출성능이 떨어짐 (V3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5490d36",
   "metadata": {},
   "source": [
    "### 처리 순서\n",
    "1. 이미지 주입 \n",
    "- 일반 이미지, 웹캠 스트림, 컴퓨터 캡처, 영상 등 ndarray로 치환할 수 있다면 사용 가능\n",
    "2. S x S 로 이미지 나누기 (그리드)\n",
    "3. 각 그리드에서 예측을 한 후 이를 종합해서 bounding box를 구성"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3c4f266",
   "metadata": {},
   "source": [
    "### YOLO 사용법\n",
    "- 딥러닝 프레임워크가 제공하면 해당 프레임워크를 사용\n",
    "\n",
    "\n",
    "1. Darknet : YOLO 개발자가 만든 프레임워크 - YOLO를 위해 특별히 제작\n",
    "- 코랩은 Darknet을 사용하면 됨\n",
    "- 장점 : 빠르다. GPU 또는 CPU와 함께 사용가능\n",
    "- 단점 : 리눅스에서만 호환됨\n",
    "\n",
    "\n",
    "2. Darkflow : Darknet을 텐서플로우에 적용한것\n",
    "- 장점 : 빠르고 GPU 또는 CPU와 함께 사용 가능하고 리눅스, 윈도우, 맥에서 호환\n",
    "- 단점 : 설치 복잡\n",
    "\n",
    "\n",
    "3. OpenCV : 최소 3.4.2버전 필요\n",
    "- 장점 : openCV외에 설치만 필요\n",
    "- 단점 : CPU에서만 작동하기 때문에 비디오를 실시간으로 처리하는 데 속도가 빠르진 않다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25952505",
   "metadata": {},
   "source": [
    "### OpenCV DNN YOLO 사용하기 (사용법 위주)\n",
    "- yolo 사이트에서 기 학습된 모델의 weight와 conf 파일을 받아와야 함\n",
    "- https://pjreddie.com/darknet/yolo/\n",
    "- weight file : 훈련된 모델\n",
    "- cfg file : 구성 파일 (모델 구성 파일)\n",
    "- name files : 모델이 감지할 수 있는 객체명"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f345ee",
   "metadata": {},
   "source": [
    "### 사용 데이터셋\n",
    "- 자동차 인식 데이터셋 (캐글 데이터)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "692debe5",
   "metadata": {},
   "source": [
    "### Open CV : 비전 처리 패키지를 활용한 YOLO 모델 구현\n",
    "- 기 학습된 모델 활용\n",
    "- 가중치 파일과 구성파일 활용\n",
    "- cv.dnn.readNet(가중치 파일, 구성 파일)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf8ea9e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/lab06/Deep_Learning\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c380268e",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = cv2.dnn.readNet('yolov3.weights', 'yolov3.cfg')  # 기 학습된 모델"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc025bb8",
   "metadata": {},
   "source": [
    "### yolov3 라벨\n",
    "- ms coco 데이터셋을 사용하는 구조 : classes 수가 80\n",
    "- 해당 데이터셋 라벨 파일 읽어서 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6c87629",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<function str.strip>,\n",
       " <function str.strip>,\n",
       " <function str.strip>,\n",
       " <function str.strip>,\n",
       " <function str.strip>,\n",
       " <function str.strip>,\n",
       " <function str.strip>,\n",
       " <function str.strip>,\n",
       " <function str.strip>,\n",
       " <function str.strip>,\n",
       " <function str.strip>,\n",
       " <function str.strip>,\n",
       " <function str.strip>,\n",
       " <function str.strip>,\n",
       " <function str.strip>,\n",
       " <function str.strip>,\n",
       " <function str.strip>,\n",
       " <function str.strip>,\n",
       " <function str.strip>,\n",
       " <function str.strip>,\n",
       " <function str.strip>,\n",
       " <function str.strip>,\n",
       " <function str.strip>,\n",
       " <function str.strip>,\n",
       " <function str.strip>,\n",
       " <function str.strip>,\n",
       " <function str.strip>,\n",
       " <function str.strip>,\n",
       " <function str.strip>,\n",
       " <function str.strip>,\n",
       " <function str.strip>,\n",
       " <function str.strip>,\n",
       " <function str.strip>,\n",
       " <function str.strip>,\n",
       " <function str.strip>,\n",
       " <function str.strip>,\n",
       " <function str.strip>,\n",
       " <function str.strip>,\n",
       " <function str.strip>,\n",
       " <function str.strip>,\n",
       " <function str.strip>,\n",
       " <function str.strip>,\n",
       " <function str.strip>,\n",
       " <function str.strip>,\n",
       " <function str.strip>,\n",
       " <function str.strip>,\n",
       " <function str.strip>,\n",
       " <function str.strip>,\n",
       " <function str.strip>,\n",
       " <function str.strip>,\n",
       " <function str.strip>,\n",
       " <function str.strip>,\n",
       " <function str.strip>,\n",
       " <function str.strip>,\n",
       " <function str.strip>,\n",
       " <function str.strip>,\n",
       " <function str.strip>,\n",
       " <function str.strip>,\n",
       " <function str.strip>,\n",
       " <function str.strip>,\n",
       " <function str.strip>,\n",
       " <function str.strip>,\n",
       " <function str.strip>,\n",
       " <function str.strip>,\n",
       " <function str.strip>,\n",
       " <function str.strip>,\n",
       " <function str.strip>,\n",
       " <function str.strip>,\n",
       " <function str.strip>,\n",
       " <function str.strip>,\n",
       " <function str.strip>,\n",
       " <function str.strip>,\n",
       " <function str.strip>,\n",
       " <function str.strip>,\n",
       " <function str.strip>,\n",
       " <function str.strip>,\n",
       " <function str.strip>,\n",
       " <function str.strip>,\n",
       " <function str.strip>,\n",
       " <function str.strip>]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# label 작성\n",
    "classes = []\n",
    "with open('./cardataset/coco.names.txt', 'r') as f:\n",
    "    classes = [line.strip for line in f.readlines()]\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a169ef22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['yolo_82', 'yolo_94', 'yolo_106']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# yolov3 층 확인\n",
    "layer_names = net.getLayerNames()\n",
    "# print(layer_names)\n",
    "\n",
    "output_layers = [layer_names[i[0]-1] for i in net.getUnconnectedOutLayers()]\n",
    "output_layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a11131",
   "metadata": {},
   "source": [
    "### 전체 모델 layer에서 82, 94, 106 3개의 yolo 출력을 반환함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d9b457cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 객체 검출 이미지\n",
    "img = cv2.imread('cardataset/training_images/vid_4_10000.jpg')\n",
    "\n",
    "# 이미지 BGR 형태로 읽어오므로 RGB로 변환\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "height, width, channels = img.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8fd141a",
   "metadata": {},
   "source": [
    "- 네트워크(모델)에서 이미지를 바로 사용할 수 없기 때문에 모델에 맞는 이미지 파일로 변경해야 함\n",
    "    - yolo는 Blob 파일을 사용\n",
    "    - cv2.dnn.blobFromImage(img, scalefactor=1/255.0, size=(416, 416), swapRB=True, crop=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "faf5ce53",
   "metadata": {},
   "outputs": [],
   "source": [
    "blob = out = cv2.dnn.blobFromImage(img, scalefactor=1/255.0, size=(416, 416), swapRB=True, crop=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4ea7d49b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(1, 3, 416, 416)\n",
      "519168\n"
     ]
    }
   ],
   "source": [
    "print(type(out))\n",
    "print(out.shape)\n",
    "print(out.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "78f0b157",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 해당 이미지 모델에 주입\n",
    "net.setInput(blob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a92efa59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 객체 검출 : forward()\n",
    "outs = net.forward(output_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "50cdfbe5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[0.0466555 , 0.03448524, 0.28790614, ..., 0.        , 0.        ,\n",
       "         0.        ],\n",
       "        [0.05441702, 0.03707229, 0.22892022, ..., 0.        , 0.        ,\n",
       "         0.        ],\n",
       "        [0.05506101, 0.02748125, 0.96016824, ..., 0.        , 0.        ,\n",
       "         0.        ],\n",
       "        ...,\n",
       "        [0.9540115 , 0.9486618 , 0.32916814, ..., 0.        , 0.        ,\n",
       "         0.        ],\n",
       "        [0.96471244, 0.9620062 , 0.2737023 , ..., 0.        , 0.        ,\n",
       "         0.        ],\n",
       "        [0.97067446, 0.9627972 , 0.7975585 , ..., 0.        , 0.        ,\n",
       "         0.        ]], dtype=float32),\n",
       " array([[0.02570593, 0.02167369, 0.05852114, ..., 0.        , 0.        ,\n",
       "         0.        ],\n",
       "        [0.01919862, 0.02305201, 0.25821224, ..., 0.        , 0.        ,\n",
       "         0.        ],\n",
       "        [0.02805037, 0.01867389, 0.08982707, ..., 0.        , 0.        ,\n",
       "         0.        ],\n",
       "        ...,\n",
       "        [0.9745448 , 0.97639394, 0.05165857, ..., 0.        , 0.        ,\n",
       "         0.        ],\n",
       "        [0.9801102 , 0.9750267 , 0.29373997, ..., 0.        , 0.        ,\n",
       "         0.        ],\n",
       "        [0.9796879 , 0.9825116 , 0.07998363, ..., 0.        , 0.        ,\n",
       "         0.        ]], dtype=float32),\n",
       " array([[0.0088212 , 0.00447751, 0.02081572, ..., 0.        , 0.        ,\n",
       "         0.        ],\n",
       "        [0.0096868 , 0.01100317, 0.01725168, ..., 0.        , 0.        ,\n",
       "         0.        ],\n",
       "        [0.00949479, 0.00694836, 0.19921263, ..., 0.        , 0.        ,\n",
       "         0.        ],\n",
       "        ...,\n",
       "        [0.9910192 , 0.9914112 , 0.01345128, ..., 0.        , 0.        ,\n",
       "         0.        ],\n",
       "        [0.9898007 , 0.9878328 , 0.01932423, ..., 0.        , 0.        ,\n",
       "         0.        ],\n",
       "        [0.9870233 , 0.99086446, 0.1745549 , ..., 0.        , 0.        ,\n",
       "         0.        ]], dtype=float32)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "29d9b20e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv_outs type : list, cv_outs length :  3\n"
     ]
    }
   ],
   "source": [
    "print('cv_outs type : list, cv_outs length : ', len(outs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4804e442",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "85"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outs[0]  # 그리드 13 X 13\n",
    "outs[1]  # 그리드 26 X 26\n",
    "len(outs[2][0])  # 52 X 52뒤쪽 출력일수록 이미지를 더 작게 분할해서 학습\n",
    "\n",
    "# 각 classes별 확률(80), 바운딩박스좌표, confidence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d92a6bf",
   "metadata": {},
   "source": [
    "### bounding box 그리기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "faf99be6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2\n",
      "0.9849074\n",
      "[0.10192333 0.56282794 0.13678345 0.08634763 0.9976587 ]\n"
     ]
    }
   ],
   "source": [
    "# 정보를 화면에 표시\n",
    "class_ids = []\n",
    "confidences = []\n",
    "boxes = []\n",
    "n=0\n",
    "for out in outs:\n",
    "    n += 1\n",
    "    for detection in out:\n",
    "        scores = detection[5:]\n",
    "        class_id = np.argmax(scores)        \n",
    "        confidence = scores[class_id]\n",
    "        \n",
    "        if confidence > 0.5:\n",
    "            # Object detected\n",
    "            print(n)\n",
    "            print(class_id)                      \n",
    "            print(confidence)\n",
    "            print(detection[:5])\n",
    "            # img를 blob 화 하면서 scaling이 진행되었으므로 이미지 원 크기에 비례해서 조정해야 함\n",
    "            center_x = int(detection[0] * width)\n",
    "            center_y = int(detection[1] * height)\n",
    "            w = int(detection[2] * width)\n",
    "            h = int(detection[3] * height)\n",
    "            # 좌표(중심좌표에서 w,h의 50%만큼 감소)\n",
    "            x = int(center_x - w / 2)\n",
    "            y = int(center_y - h / 2)\n",
    "            boxes.append([x, y, w, h])\n",
    "            confidences.append(float(confidence))\n",
    "            class_ids.append(class_id)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:aws_neuron_tensorflow_p36]",
   "language": "python",
   "name": "conda-env-aws_neuron_tensorflow_p36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
